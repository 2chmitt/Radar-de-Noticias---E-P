from fastapi import FastAPI, Query
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
import feedparser
from datetime import datetime, timedelta, timezone
import os
import urllib.parse

app = FastAPI()

# =========================
# CORS
# =========================
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# =========================
# FRONTEND (static)
# =========================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
FRONTEND_DIR = os.path.join(BASE_DIR, "..", "frontend")

from starlette.responses import Response
from starlette.staticfiles import StaticFiles

class NoCacheStaticFiles(StaticFiles):
    async def get_response(self, path, scope):
        response = await super().get_response(path, scope)
        response.headers["Cache-Control"] = "no-store"
        return response

app.mount("/static", NoCacheStaticFiles(directory=FRONTEND_DIR), name="static")


@app.get("/")
def serve_index():
    return FileResponse(os.path.join(FRONTEND_DIR, "index.html"))

@app.get("/fpm")
def serve_fpm():
    return FileResponse(os.path.join(FRONTEND_DIR, "fpm.html"))

@app.get("/sobre")
def serve_sobre():
    return FileResponse(os.path.join(FRONTEND_DIR, "sobre.html"))

# =========================
# CONFIG
# =========================
MIN_RELEVANCIA = 1
TZ_BRASIL = timezone(timedelta(hours=-3))

# =========================
# PUBLISHERS
# =========================
ROYALTIES_PUBLISHERS = [
    "Valor EconÃ´mico","Reuters","AgÃªncia Brasil","g1","EstadÃ£o","Folha",
    "O Globo","CNN Brasil","InfoMoney","Petrobras","ANP",
    "AgÃªncia Nacional do PetrÃ³leo","IBAMA","Portos e Navios",
    "Brasil Energia","Offshore Energy","BNAmericas","Eixos","epbr",
]

FPM_PUBLISHERS = [
    # originais
    "AgÃªncia Brasil","g1","EstadÃ£o","Folha","O Globo","UOL",
    "CNN Brasil","InfoMoney","Valor EconÃ´mico","Consultor JurÃ­dico",
    "ConJur","CNM","ConfederaÃ§Ã£o Nacional de MunicÃ­pios",
    "IBGE","STF","STJ","TCU","AgÃªncia Senado",
    "CÃ¢mara dos Deputados","Senado",

    # fortalecimento institucional
    "Portal da TransparÃªncia",
    "MinistÃ©rio da Fazenda",
    "MinistÃ©rio do Planejamento",
    "Tesouro Nacional",
    "Secretaria do Tesouro Nacional",
    "Gov.br",
    "Planalto",
    "DiÃ¡rio Oficial da UniÃ£o",
    "DiÃ¡rio Oficial",
    "Tribunal de Contas da UniÃ£o",
    "Tribunal de Contas",
    "CNM NotÃ­cias",
    "AgÃªncia CÃ¢mara",
    "AgÃªncia Senado NotÃ­cias",
]


# =========================
# TERMOS (ORIGINAIS COMPLETOS)
# =========================
ROYALTIES_TERMS = [
    "royalties","royalties de petrÃ³leo","royalties do petrÃ³leo",
    "royalties gÃ¡s natural","royalties de gÃ¡s natural",
    "participaÃ§Ã£o especial","compensaÃ§Ã£o financeira",
    "anp","agÃªncia nacional do petrÃ³leo","gÃ¡s natural",
    "exploraÃ§Ã£o de petrÃ³leo","exploraÃ§Ã£o de gÃ¡s natural",
    "processo judicial anp","processo judicial royalties de petrÃ³leo",
    "processo judicial royalties gÃ¡s natural","exploraÃ§Ã£o","produÃ§Ã£o",
    "perfuraÃ§Ã£o","poÃ§o","poÃ§o exploratÃ³rio","sÃ­smica",
    "levantamento sÃ­smico","bloco exploratÃ³rio","oferta permanente",
    "leilÃ£o anp","rodada anp","contrato de concessÃ£o",
    "contrato de partilha","campo","campo produtor",
    "entrada em produÃ§Ã£o","ramp-up","offshore","onshore",
    "plataforma","plataforma de petrÃ³leo","fpso","navio-plataforma",
    "sonda","sonda de perfuraÃ§Ã£o","gasoduto","oleoduto",
    "terminal marÃ­timo","escoamento de produÃ§Ã£o","prÃ©-sal","presal",
    "margem equatorial","bacia da foz do amazonas",
    "bacia de campos","bacia de santos","bacia potiguar",
    "bacia de sergipe-alagoas","bacia do recÃ´ncavo",
    "bacia do parnaÃ­ba","municÃ­pios confrontantes",
    "redistribuiÃ§Ã£o de royalties","lei dos royalties",
    "aÃ§Ã£o judicial","stf","stj","tcu","vazamento de Ã³leo",
    "derramamento de Ã³leo","incidente em plataforma",
    "paralisaÃ§Ã£o de produÃ§Ã£o",
]

FPM_TERMS = [
    # termos originais
    "fpm","fundo de participaÃ§Ã£o dos municipios",
    "fundo de participaÃ§Ã£o dos municÃ­pios",
    "fundo de participaÃ§Ã£o municipal","ibge","censo",
    "processo judicial fpm","majoraÃ§Ã£o do coeficiente",
    "coeficiente do fpm","coeficiente fpm",
    "coeficiente populacional","repasse fpm",
    "transferÃªncia constitucional","revisÃ£o do coeficiente",

    # fortalecimento institucional
    "transferÃªncias constitucionais",
    "transferÃªncia intergovernamental",
    "receita municipal",
    "receitas municipais",
    "arrecadaÃ§Ã£o municipal",
    "finanÃ§as municipais",
    "orÃ§amento municipal",
    "orÃ§amento dos municÃ­pios",
    "partilha de recursos",
    "redistribuiÃ§Ã£o do fpm",
    "quota do fpm",
    "quota-parte do fpm",

    # IBGE e dados demogrÃ¡ficos
    "estimativa populacional",
    "populaÃ§Ã£o estimada",
    "dados do ibge",
    "divulgaÃ§Ã£o do censo",
    "revisÃ£o populacional",
    "atualizaÃ§Ã£o populacional",
    "contagem populacional",
    "projeÃ§Ã£o populacional",

    # jurÃ­dico
    "aÃ§Ã£o no stf sobre fpm",
    "aÃ§Ã£o no stj sobre fpm",
    "decisÃ£o judicial fpm",
    "liminar fpm",
    "mandado de seguranÃ§a fpm",
    "controle de constitucionalidade fpm",
    "artigo 159 da constituiÃ§Ã£o",
    "constituiÃ§Ã£o federal art 159",
    "tribunal de contas da uniÃ£o fpm",
    "tcu fpm",

    # CNM / municipalismo
    "confederaÃ§Ã£o nacional de municÃ­pios",
    "cnm fpm",
    "movimento municipalista",
    "municipalismo",
    "prefeituras",
    "prefeitos",
    "impacto do fpm",
    "queda do fpm",
    "aumento do fpm",

    # economia pÃºblica
    "receita corrente lÃ­quida",
    "equilÃ­brio fiscal municipal",
    "responsabilidade fiscal municÃ­pios",
    "lei de responsabilidade fiscal",
    "impacto orÃ§amentÃ¡rio fpm",

    # polÃ­tico-institucional
    "cÃ¢mara dos deputados fpm",
    "senado fpm",
    "comissÃ£o de finanÃ§as e tributaÃ§Ã£o",
    "reforma tributÃ¡ria municÃ­pios",
    "pacto federativo",
]

# =========================
# FUNÃ‡Ã•ES ORIGINAIS
# =========================
def calcular_relevancia(texto: str, termos) -> int:
    t = (texto or "").lower()
    score = 0
    for termo in termos:
        if termo.lower() in t:
            score += 1
    return score

def get_publisher(entry) -> str:
    title = getattr(entry, "title", "") or ""
    if " - " in title:
        return title.rsplit(" - ", 1)[-1].strip()
    return ""

def publisher_valido(publisher: str, lista) -> bool:
    if not publisher:
        return False
    p = publisher.lower()
    return any(item.lower() in p for item in lista)

def janela_datas(dias: int):
    agora = datetime.now(TZ_BRASIL)
    if dias == 1:
        inicio = agora.replace(hour=0, minute=0, second=0, microsecond=0)
        fim = agora.replace(hour=23, minute=59, second=59, microsecond=999999)
    else:
        inicio = agora - timedelta(days=dias)
        fim = agora
    return inicio, fim

# =========================
# MÃ‰TODO GOOGLE (ORIGINAL)
# =========================
def buscar_google(dias, termos, publishers, queries):
    inicio, fim = janela_datas(dias)
    resultados = []
    vistos = set()

    for q in queries:
        query = urllib.parse.quote(q)
        url = (
            "https://news.google.com/rss/search?"
            f"q={query}&hl=pt-BR&gl=BR&ceid=BR:pt-419"
        )
        feed = feedparser.parse(url)

        for entry in feed.entries:
            if not entry.get("published_parsed"):
                continue

            data_utc = datetime(*entry.published_parsed[:6], tzinfo=timezone.utc)
            data_pub = data_utc.astimezone(TZ_BRASIL)

            if not (inicio <= data_pub <= fim):
                continue

            link = getattr(entry, "link", "") or ""
            if not link or link in vistos:
                continue
            vistos.add(link)

            publisher = get_publisher(entry)
            if not publisher_valido(publisher, publishers):
                continue

            texto = f"{getattr(entry,'title','')} {getattr(entry,'summary','')}"
            relev = calcular_relevancia(texto, termos)
            if relev < MIN_RELEVANCIA:
                continue

            resultados.append({
                "titulo": getattr(entry, "title", ""),
                "link": link,
                "data": data_pub.strftime("%d/%m/%Y"),
                "fonte": publisher,
                "relevancia": relev
            })

    resultados.sort(key=lambda x: (x["relevancia"], x["data"]), reverse=True)
    return resultados

# =========================
# RSS DIRETO
# =========================
RSS_FEEDS_ROYALTIES = [
    "https://g1.globo.com/rss/g1/economia/",
    "https://agenciabrasil.ebc.com.br/rss/economia/feed.xml",
    "https://www.infomoney.com.br/feed/",
]

RSS_FEEDS_FPM = [
    "https://agenciabrasil.ebc.com.br/rss/politica/feed.xml",
    "https://www.cnm.org.br/rss",
]

def buscar_rss(dias, termos, publishers, feeds):
    inicio, fim = janela_datas(dias)
    resultados = []
    vistos = set()

    for feed_url in feeds:
        feed = feedparser.parse(feed_url)

        for entry in feed.entries:
            if not entry.get("published_parsed"):
                continue

            data_utc = datetime(*entry.published_parsed[:6], tzinfo=timezone.utc)
            data_pub = data_utc.astimezone(TZ_BRASIL)

            if not (inicio <= data_pub <= fim):
                continue

            link = getattr(entry, "link", "") or ""
            if not link or link in vistos:
                continue
            vistos.add(link)

            publisher = feed.feed.get("title", "RSS")
            if not publisher_valido(publisher, publishers):
                continue

            texto = f"{getattr(entry,'title','')} {getattr(entry,'summary','')}"
            relev = calcular_relevancia(texto, termos)
            if relev < MIN_RELEVANCIA:
                continue

            resultados.append({
                "titulo": getattr(entry, "title", ""),
                "link": link,
                "data": data_pub.strftime("%d/%m/%Y"),
                "fonte": publisher,
                "relevancia": relev
            })

    resultados.sort(key=lambda x: (x["relevancia"], x["data"]), reverse=True)
    return resultados

# =========================
# BING
# =========================

from urllib.parse import urlparse, urlunparse

def buscar_bing(dias, termos, publishers, queries):
    inicio, fim = janela_datas(dias)
    resultados = []
    vistos = set()

    for q in queries:
        query = urllib.parse.quote(q)
        url = f"https://www.bing.com/news/search?q={query}&format=rss"
        feed = feedparser.parse(url)

        for entry in feed.entries:
            if not entry.get("published_parsed"):
                continue

            data_utc = datetime(*entry.published_parsed[:6], tzinfo=timezone.utc)
            data_pub = data_utc.astimezone(TZ_BRASIL)

            if not (inicio <= data_pub <= fim):
                continue

            link_original = getattr(entry, "link", "") or ""
            if not link_original:
                continue

            # ðŸ”¥ NORMALIZA LINK (REMOVE TRACKING DO BING)
            parsed = urlparse(link_original)
            link_limpo = urlunparse((parsed.scheme, parsed.netloc, parsed.path, '', '', ''))

            # ðŸ”¥ CONTROLE DE DUPLICAÃ‡ÃƒO
            if link_limpo in vistos:
                continue
            vistos.add(link_limpo)

            publisher = "Bing News"

            texto = f"{getattr(entry,'title','')} {getattr(entry,'summary','')}"
            relev = calcular_relevancia(texto, termos)
            if relev < MIN_RELEVANCIA:
                continue

            resultados.append({
                "titulo": getattr(entry, "title", ""),
                "link": link_original,  # mantÃ©m link original para o usuÃ¡rio
                "data": data_pub.strftime("%d/%m/%Y"),
                "fonte": publisher,
                "relevancia": relev
            })

    resultados.sort(key=lambda x: (x["relevancia"], x["data"]), reverse=True)
    return resultados


# =========================
# ENDPOINTS
# =========================
@app.get("/buscar-royalties")
def buscar_royalties(
    dias: int = Query(7, ge=1, le=60),
    metodo: str = Query("google")
):

    queries = [
        "royalties de petrÃ³leo Brasil",
        "royalties gÃ¡s natural Brasil",
        "ANP royalties",
        "AgÃªncia Nacional do PetrÃ³leo royalties",
        "exploraÃ§Ã£o de petrÃ³leo Brasil",
        "exploraÃ§Ã£o de gÃ¡s natural Brasil",
        "processo judicial ANP",
        "processo judicial royalties de petrÃ³leo",
        "processo judicial royalties gÃ¡s natural",
        "participaÃ§Ã£o especial petrÃ³leo municÃ­pios",
        "margem equatorial petrÃ³leo",
        "bacia da foz do amazonas petrÃ³leo",
        "produÃ§Ã£o de petrÃ³leo offshore Brasil",
        "oferta permanente ANP blocos",
        "leilÃ£o ANP petrÃ³leo gÃ¡s",
    ]

    if metodo == "rss":
        resultados = buscar_rss(dias, ROYALTIES_TERMS, ROYALTIES_PUBLISHERS, RSS_FEEDS_ROYALTIES)
    elif metodo == "bing":
        resultados = buscar_bing(dias, ROYALTIES_TERMS, ROYALTIES_PUBLISHERS, queries)
    else:
        resultados = buscar_google(dias, ROYALTIES_TERMS, ROYALTIES_PUBLISHERS, queries)

    return {
        "tipo": "Royalties de PetrÃ³leo",
        "periodo": "Hoje" if dias == 1 else f"Ãšltimos {dias} dias",
        "metodo": metodo.capitalize(),
        "quantidade": len(resultados),
        "noticias": resultados
    }

@app.get("/buscar-fpm")
def buscar_fpm(
    dias: int = Query(7, ge=1, le=60),
    metodo: str = Query("google")
):

    queries = [
       # base direta
    "FPM",
    "Fundo de ParticipaÃ§Ã£o dos MunicÃ­pios",
    "Fundo de participaÃ§Ã£o municipal",

    # repasses
    "repasse do FPM",
    "repasse FPM municÃ­pios",
    "repasse federal municÃ­pios",
    "transferÃªncia do FPM",
    "transferÃªncias constitucionais municÃ­pios",
    "Tesouro Nacional FPM",
    "Secretaria do Tesouro Nacional FPM",

    # linguagem jornalÃ­stica
    "municÃ­pios recebem FPM",
    "prefeituras recebem FPM",
    "queda do FPM",
    "aumento do FPM",
    "valor do FPM",
    "terceiro decÃªndio do FPM",
    "segundo decÃªndio do FPM",
    "primeiro decÃªndio do FPM",

    # IBGE e coeficiente
    "coeficiente do FPM IBGE",
    "revisÃ£o coeficiente FPM",
    "estimativa populacional IBGE municÃ­pios",
    "censo IBGE impacto FPM",
    "majoraÃ§Ã£o coeficiente FPM",

    # legislativo e judicial
    "projeto de lei FPM",
    "STF FPM decisÃ£o",
    "STJ FPM decisÃ£o",
    "TCU FPM",
    "aÃ§Ã£o judicial FPM",

    # contexto econÃ´mico
    "orÃ§amento municipal FPM",
    "arrecadaÃ§Ã£o municipal FPM",
    "receita municipal FPM",
    "impacto do FPM nos municÃ­pios",

    # pacto federativo
    "pacto federativo municÃ­pios",
    "reforma tributÃ¡ria municÃ­pios FPM",
    ]

    if metodo == "rss":
        resultados = buscar_rss(dias, FPM_TERMS, FPM_PUBLISHERS, RSS_FEEDS_FPM)
    elif metodo == "bing":
        resultados = buscar_bing(dias, FPM_TERMS, FPM_PUBLISHERS, queries)
    else:
        resultados = buscar_google(dias, FPM_TERMS, FPM_PUBLISHERS, queries)

    return {
        "tipo": "FPM",
        "periodo": "Hoje" if dias == 1 else f"Ãšltimos {dias} dias",
        "metodo": metodo.capitalize(),
        "quantidade": len(resultados),
        "noticias": resultados
    }
